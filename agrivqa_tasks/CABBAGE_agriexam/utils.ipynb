{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import requests\n",
    "import yaml\n",
    "from loguru import logger as eval_logger\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "task_name = 'AgriExam'\n",
    "folder = '/workdir/important_datasets/AGRIVQA/'\n",
    "dataset_name = \"parquet\"\n",
    "data_files = {\n",
    "    \"dev\": folder+task_name+\"/dev-00000-of-00001.parquet\",\n",
    "    \"test\": folder+task_name+\"/test-00000-of-00001.parquet\",\n",
    "    \"validation\": folder+task_name+\"/validation-00000-of-00001.parquet\"\n",
    "}\n",
    "split = \"dev\"\n",
    "\n",
    "dataset = load_dataset(dataset_name,data_files=data_files, split=split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, the .yaml file is read and converted into a dictionary named config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__= \"/workdir/agrivqa_tasks/CABBAGE_agriexam/CABBAGE_agriexam.yaml\"\n",
    "\n",
    "#rule_dict = json.load(open(os.path.join(os.path.dirname(os.path.abspath(__file__)), \"rule.json\"), \"r\"))\n",
    "\n",
    "with open(Path(__file__).parent / \"CABBAGE_agriexam.yaml\", \"r\") as f:\n",
    "    raw_data = f.readlines()\n",
    "    safe_data = []\n",
    "    for i, line in enumerate(raw_data):\n",
    "        # remove function definition since yaml load cannot handle it\n",
    "        if \"!function\" not in line:\n",
    "            safe_data.append(line)\n",
    "\n",
    "    config = yaml.safe_load(\"\".join(safe_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, as with all other tasks, the visuals and text are prepared for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_options(options):\n",
    "    option_letters = [chr(ord(\"A\") + i) for i in range(len(options))]\n",
    "    choices_str = \"\\n\".join([f\"{option_letter}. {option}\" for option_letter, option in zip(option_letters, options)])\n",
    "    return choices_str\n",
    "\n",
    "def CABBAGE_AgriExam_doc_to_text(doc, lmms_eval_specific_kwargs=None):\n",
    "    question = doc['question']\n",
    "    if lmms_eval_specific_kwargs is None:\n",
    "        lmms_eval_specific_kwargs = {}\n",
    "    pre_prompt = lmms_eval_specific_kwargs.get(\"pre_prompt\", \"\")\n",
    "    post_prompt = lmms_eval_specific_kwargs.get(\"post_prompt\", \"\")\n",
    "    if doc['options']:\n",
    "        options = parse_options(doc['options'])\n",
    "        return f\"{pre_prompt}\\nQuestion: {question}\\n\\nOptions:\\n{options}\\n{post_prompt}\"\n",
    "    return f\"{pre_prompt}\\n\\nQuestion: {question}{post_prompt}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: Study of grasses?\n",
      "\n",
      "Options:\n",
      "A. Agroforestry\n",
      "B. Agronomy\n",
      "C. Zoology\n",
      "D. Agrostology\n",
      "E. All of above\n",
      "\n",
      "Answer with the option's letter from the given choices directly.\n"
     ]
    }
   ],
   "source": [
    "doc = dataset[3]\n",
    "print(CABBAGE_AgriExam_doc_to_text(doc,config['lmms_eval_specific_kwargs']['default']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CABBAGE_AgriExam_process_results(doc, results):\n",
    "    # I know this is weird, but it's how llava parse it.\n",
    "    target = doc['answer'].strip().lower()\n",
    "    pred = results[0].strip().lower()\n",
    "    if pred == target:\n",
    "        return {\"exact_match\": 1.0}\n",
    "    # pattern: ^[A-Z]\\. .*\n",
    "    if len(pred) >= 2 and pred[1] == \".\":\n",
    "        result = 1.0 if pred[0] == target else 0.0\n",
    "        return {\"exact_match\": result}\n",
    "    return {\"exact_match\": 0.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'dev_AgriExam_4',\n",
       " 'question': 'Study of grasses?',\n",
       " 'options': ['Agroforestry',\n",
       "  'Agronomy',\n",
       "  'Zoology',\n",
       "  'Agrostology',\n",
       "  'All of above'],\n",
       " 'answer': 'D',\n",
       " 'category': 'Plant Taxonomy and Scientific Naming',\n",
       " 'question_type': 'multiple-choice',\n",
       " 'metadata': {'language': 'English',\n",
       "  'license': '',\n",
       "  'source': 'AgriExam',\n",
       "  'url': 'https://www.agriexam.com/agriculture-field-officer-2015',\n",
       "  'verbose_answer': 'Agrostology'}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred='D.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 1.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CABBAGE_AgriExam_process_results(doc, ['D.'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
